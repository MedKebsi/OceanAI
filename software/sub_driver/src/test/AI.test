#include "../tensorflow/temp_model.h"

#include <tensorflow/lite/micro/micro_interpreter.h>
#include <tensorflow/lite/micro/micro_error_reporter.h>
#include <tensorflow/lite/version.h>
#include <tensorflow/lite/micro/micro_mutable_op_resolver.h>
#include <tensorflow/lite/micro/all_ops_resolver.h>

#include "config.h"

#include <Arduino.h>

namespace
{
    tflite::ErrorReporter *error_reporter = nullptr;
    const tflite::Model *model = nullptr;
    tflite::MicroInterpreter *interpreter = nullptr;
    TfLiteTensor *model_input = nullptr;
    TfLiteTensor *model_output = nullptr;
    int inference_count = 0;

    // Create an area of memory to use for input, output, and intermediate arrays.
    constexpr int kTensorArenaSize = 5 * 1024;
    uint8_t tensor_arena[kTensorArenaSize];
}

void setup()
{
    #if DEBUG_ON
        Serial.begin(115200);
        while (!Serial);
    #endif
    static tflite::MicroErrorReporter micro_error_reporter;
    error_reporter = &micro_error_reporter;

    model = tflite::GetModel(temp_model);
    if (model->version() != TFLITE_SCHEMA_VERSION)
    {
        TF_LITE_REPORT_ERROR(error_reporter, "Model provided is schema version %d not equal to supported version %d.", model->version(), TFLITE_SCHEMA_VERSION);
        return;
    }

    static tflite::MicroMutableOpResolver<1> micro_op_resolver;
    micro_op_resolver.AddFullyConnected();

    static tflite::MicroInterpreter static_interpreter(model, micro_op_resolver, tensor_arena, kTensorArenaSize, error_reporter);

    interpreter = &static_interpreter;
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk)
    {
        TF_LITE_REPORT_ERROR(error_reporter, "AllocateTensors() failed");
        return;
    }

    model_input = interpreter->input(0);
    model_output = interpreter->output(0);

    #if DEBUG_ON
        
    #endifSerial.print("Number of dimensions: "); Serial.println(model_input->dims->size);
        Serial.print("Dim 1 size: "); Serial.println(model_input->dims->data[0]);
        Serial.print("Dim 2 size: "); Serial.println(model_input->dims->data[1]);
        Serial.print("Input type: "); Serial.println(model_input->type);

}

double input[4] = {100.935616, 1.0261427, 10.0350, 33.6333};

void loop()
{
    #if DEBUG_ON
        unsigned long start = micros();
    #endif


    for(int i = 0; i < 4; i++)
    {
        model_input->data.f[i] = input[i];
    }

    TfLiteStatus invoke_status = interpreter->Invoke();
    if (invoke_status != kTfLiteOk)
    {
        error_reporter->Report("Invoke failed on index: %d", model_input);
        return;
    }

    double output = model_output->data.f[0];

    #if DEBUG_ON
        unsigned long end = micros();
        Serial.print("Inference time: "); Serial.print(end - start); Serial.println(" us");
        Serial.print("Model Output: "); Serial.println(output);
        Serial.print("\n");
        delay(1000);
    #endif


}